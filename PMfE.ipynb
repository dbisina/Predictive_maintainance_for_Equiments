{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, fbeta_score\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data_path = 'https://raw.githubusercontent.com/Rapo-zevs/eda/main/predictive_maintenance.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "n = data.shape[0]\n",
    "# First checks\n",
    "\n",
    "data.info()\n",
    "print('Number of null values is: {}'.format(data.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set numeric columns dtype to float\n",
    "data['Tool wear [min]'] = data['Tool wear [min]'].astype('float64')\n",
    "data['Rotational speed [rpm]'] = data['Rotational speed [rpm]'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID columns\n",
    "df = data.copy()\n",
    "df.drop(columns=['UDI','Product ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pie chart shows the percentages of machines by Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = data['Type'].value_counts()\n",
    "Type_Percentage = 100*value/data.Type.shape[0]\n",
    "labels = Type_Percentage.index.array\n",
    "x = Type_Percentage.array\n",
    "custom_colors = sns.color_palette('Set3', len(labels))\n",
    "plt.pie(x, labels=labels, colors=custom_colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Machine Type percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aberrations Create lists of features and target names\n",
    "df.dtypes\n",
    "features = [col for col in df.columns if df[col].dtype=='float64' or col =='Type']\n",
    "target = ['Target','Failure Type']\n",
    "# Portion of data where Random Failure=1\n",
    "random_fail_index=df.loc[df['Failure Type']=='Random Failures'].index\n",
    "df.loc[random_fail_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately the machine failure RNF occurs in only 18 observations and it has a random nature\n",
    "therefore not predictable so we decide to remove these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RNF\n",
    "df.drop(index=random_fail_index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward we find out that in 9 observations Machine failure is set to 1 when all types\n",
    "of failures are set to 0. We cannot understand if there really was a failure or not so letâ€™s remove\n",
    "these observations too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portion of data where Machine failure=1 but no failure cause is specified\n",
    "ambiguous_index = df.loc[(df['Target']==1) & (df['Failure Type']=='No Failure')].index\n",
    "second_drop = df.loc[ambiguous_index].shape[0]\n",
    "display(df.loc[ambiguous_index,target])\n",
    "df.drop(index=ambiguous_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global percentage of removed observations\n",
    "print('Global percentage of removed observations:',\n",
    "     (100*(data.size-df.size)/data.size))\n",
    "df.reset_index(drop=True, inplace=True)   # Reset index\n",
    "n = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers inspection <a id=\"outliers\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [feature for feature in features if df[feature].dtype=='float64']\n",
    "# boxplot of numeric features\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18,7))\n",
    "fig.suptitle('Numeric features boxplot')\n",
    "for j, feature in enumerate(num_features):\n",
    "    sns.boxplot(ax=axs[j//3, j-3*(j//3)], data=df, x=feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers_custom(dataframe, column_name, lower_threshold, upper_threshold):\n",
    "    # Filter the DataFrame to keep only the data points within the specified range\n",
    "    dataframe_filtered = dataframe[(dataframe[column_name] >= lower_threshold) & (dataframe[column_name] <= upper_threshold)]\n",
    "    return dataframe_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_outliers_custom(df, 'Rotational speed [rpm]', 1300, 2250)\n",
    "sns.boxplot(x='Rotational speed [rpm]', data=df)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_outliers_custom(df, 'Torque [Nm]', 12, 73)\n",
    "sns.boxplot(x='Torque [Nm]', data=df)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling with SMOTE <a id=\"resampling\"></a>\n",
    "\n",
    "Another important consideration regards the extremely low occurrence of machine failures among\n",
    "the entire dataset, which percentage is equal only to 3.31%. Moreover, a pie plot showing the\n",
    "occurrence of the causes involved for each failure reveals a further degree of imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portion of df where there is a failure and causes percentage\n",
    "fail_index = df.loc[df['Failure Type'] != 'No Failure'].index\n",
    "df_fail = df.loc[fail_index]\n",
    "df_fail_percentage = 100*df_fail['Failure Type'].value_counts()/df_fail['Failure Type'].shape[0]\n",
    "# Pie plot\n",
    "plt.title('Causes involved in Machine failures')\n",
    "plt.pie(x=df_fail_percentage.array, labels=df_fail_percentage.index.array,\n",
    "        colors=sns.color_palette('tab10')[0:4], autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "# n_working must represent 80% of the desired length of resampled dataframe\n",
    "n_working = df['Failure Type'].value_counts()['No Failure']\n",
    "desired_length = round(n_working/0.8)\n",
    "spc = round((desired_length-n_working)/4)  #samples per class\n",
    "# Resampling\n",
    "balance_cause = {'No Failure':n_working,\n",
    "                 'Overstrain Failure':spc,\n",
    "                 'Heat Dissipation Failure':spc,\n",
    "                 'Power Failure':spc,\n",
    "                 'Tool Wear Failure':spc}\n",
    "sm = SMOTENC(categorical_features=[0,7], sampling_strategy=balance_cause, random_state=0)\n",
    "df_res, y_res = sm.fit_resample(df, df['Failure Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison after resampling <a id=\"resample_comparison\"></a>\n",
    "\n",
    "The result is described in the following pie charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portion of df_res where there is a failure and causes percentage\n",
    "idx_fail_res = df_res.loc[df_res['Failure Type'] != 'No Failure'].index\n",
    "df_res_fail = df_res.loc[idx_fail_res]\n",
    "fail_res_percentage = 100*df_res_fail['Failure Type'].value_counts()/df_res_fail.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "fig.suptitle('Causes involved in Machine failures')\n",
    "\n",
    "# Create bar charts on the first subplot\n",
    "axs[0].bar(df_fail_percentage.index.array, df_fail_percentage.array, color=sns.color_palette('tab10')[0:4])\n",
    "axs[0].set_ylabel('Percentage')\n",
    "axs[0].set_title('Original')\n",
    "\n",
    "# Create bar charts on the second subplot\n",
    "axs[1].bar(fail_res_percentage.index.array, fail_res_percentage.array, color=sns.color_palette('tab10')[0:4])\n",
    "axs[1].set_ylabel('Percentage')\n",
    "axs[1].set_title('After Resampling')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features scaling and Encoding <a id=\"encoding\"></a>\n",
    "\n",
    "In order to make data exploitable for the algorithms we will run, we apply two transformations:\n",
    "* First, we apply a label encoding to the categorical columns, since Type is an ordinal feature\n",
    "and Cause must be represented in one column. The mapping follows this scheme:\n",
    "Type: {L=0, M=1, H=2}\n",
    "Cause: {Working=0, PWF=1, OSF=2, HDF=3, TWF=4}\n",
    "* Secondly we perform the scaling of the columns with StandardScaler. This is particularly\n",
    "useful for the good working of methods that rely on the metric space, such as PCA and KNN.\n",
    "It has been also verified that using StandardScaler leads to slightly better performances than\n",
    "using MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "sc = StandardScaler()\n",
    "types = {'L': 0, 'M': 1, 'H': 2}\n",
    "causes = {'No Failure': 0,'Power Failure': 1,'Overstrain Failure': 2,'Heat Dissipation Failure': 3,'Tool Wear Failure': 4}\n",
    "df_pre = df_res.copy()\n",
    "# Encoding\n",
    "df_pre['Type'].replace(to_replace=types, inplace=True)\n",
    "df_pre['Failure Type'].replace(to_replace=causes, inplace=True)\n",
    "# Scaling\n",
    "df_pre[num_features] = sc.fit_transform(df_pre[num_features]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA and Correlation Heatmap <a id=\"pca\"></a>\n",
    "\n",
    "We run PCA to have a further way of displaying the data instead of making feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=len(num_features))\n",
    "X_pca = pd.DataFrame(data=pca.fit_transform(df_pre[num_features]), columns=['PC'+str(i+1) for i in range(len(num_features))])\n",
    "var_exp = pd.Series(data=100*pca.explained_variance_ratio_, index=['PC'+str(i+1) for i in range(len(num_features))])\n",
    "print('Explained variance ratio per component:', round(var_exp,2), sep='\\n=')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings Analysis\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(18, 4))\n",
    "fig.suptitle('Loadings magnitude')\n",
    "pca_loadings = pd.DataFrame(data=pca.components_, columns=num_features)\n",
    "\n",
    "for j in range(3):\n",
    "    ax = axs[j]\n",
    "    loadings_data = pca_loadings.values[j]\n",
    "    positive_loadings = np.maximum(0, loadings_data)\n",
    "    negative_loadings = np.minimum(0, loadings_data)\n",
    "    \n",
    "    x = np.arange(len(num_features))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x, positive_loadings, width, label='Positive', color='b')\n",
    "    ax.bar(x, negative_loadings, width, label='Negative', color='r')\n",
    "    \n",
    "    ax.set_xlabel('Features')\n",
    "    ax.set_ylabel('Loadings')\n",
    "    ax.set_title('PC' + str(j + 1))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(num_features, rotation=90)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot of Principal Components weights makes easy to understand what they represent:\n",
    "* PC1 is closely related to the two temperature data;\n",
    "* PC2 can be identified with the machine power, which is the product of Rotational Speed\n",
    "and Torque;\n",
    "* PC3 is identifiable with Tool Wear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection into the space generated by these three axes highlights that:\n",
    "* TWF is the class of failures best separated from all the others and seems to depend almost\n",
    "entirely on PC3 (Tool Wear);\n",
    "* PWF occupies two extreme bands along the PC2 (Power), it is independent of the other\n",
    "two components;\n",
    "18\n",
    "* The OSF and HDF classes are less separated than the others even if it can be observed\n",
    "that the first is characterized by a high Tool Wear and low power while the second is\n",
    "characterized by a high temperature and a low power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.heatmap(data=df_pre.corr(), mask=np.triu(df_pre.corr()), annot=True, cmap='BrBG')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, we observe that the features related to temperature, as well as those related to\n",
    "power, are widely correlated. Furthermore, Tool Wear correlates well with both of our targets,\n",
    "confirming what we have observed by studying PCA. Finally, a less strong correlation is also\n",
    "observed between the torsion and the two targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Binary task** <a id=\"binary\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation-test split\n",
    "X, y = df_pre[features], df_pre[['Target','Failure Type']]\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.1, stratify=df_pre['Failure Type'], random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.11, stratify=y_trainval['Failure Type'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preds(model,X,y_true,y_pred,task):\n",
    "    if task == 'binary':\n",
    "        # Extract task target\n",
    "        y_true = y_true['Target']\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        # Probability of the minority class\n",
    "        proba = model.predict_proba(X)[:,1]\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, proba)\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "        f2 = fbeta_score(y_true, y_pred, pos_label=1, beta=2)\n",
    "        metrics = pd.Series(data={'ACC':acc, 'AUC':auc, 'F1':f1, 'F2':f2})\n",
    "    metrics = round(metrics,3)\n",
    "    return cm, metrics\n",
    "def tune_and_fit(clf,X,y,params,task):\n",
    "    if task=='binary':\n",
    "        f2_scorer = make_scorer(fbeta_score, pos_label=1, beta=2)\n",
    "        start_time = time.time()\n",
    "        grid_model = GridSearchCV(clf, param_grid=params,\n",
    "                                cv=5, scoring=f2_scorer)\n",
    "        grid_model.fit(X, y['Target'])      \n",
    "    print('Best params:', grid_model.best_params_)\n",
    "    # Print training times\n",
    "    train_time = time.time()-start_time\n",
    "    mins = int(train_time//60)\n",
    "    print('Training time: '+str(mins)+'m '+str(round(train_time-mins*60))+'s')\n",
    "    return grid_model\n",
    "def predict_and_evaluate(fitted_models, X, y_true, clf_str, task):\n",
    "    cm_dict = {key: np.nan for key in clf_str}\n",
    "    metrics = pd.DataFrame(columns=clf_str)\n",
    "    y_pred = pd.DataFrame(columns=clf_str)\n",
    "    for fit_model, model_name in zip(fitted_models, clf_str):\n",
    "        # Update predictions\n",
    "        if isinstance(fit_model, VotingClassifier) and fit_model.voting == 'hard':\n",
    "            y_pred[model_name] = fit_model.predict(X)\n",
    "        else:\n",
    "            y_pred[model_name] = fit_model.predict_proba(X)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        if task == 'binary':\n",
    "            cm, scores = eval_preds(fit_model, X, y_true,\n",
    "                                    y_pred[model_name], task)\n",
    "        cm_dict[model_name] = cm\n",
    "        metrics[model_name] = scores\n",
    "\n",
    "    return y_pred, cm_dict, metrics\n",
    "\n",
    "\n",
    "def fit_models(clf,clf_str,X_train,X_val,y_train,y_val):\n",
    "    metrics = pd.DataFrame(columns=clf_str)\n",
    "    for model, model_name in zip(clf, clf_str):\n",
    "        model.fit(X_train,y_train['Target'])\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        metrics[model_name] = eval_preds(model,X_val,y_val,y_val_pred,'binary')[1]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models <a id=\"binary_models\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "rfc = RandomForestClassifier()\n",
    "fnn = MLPClassifier(max_iter=1000)\n",
    "clf = [knn, svc, rfc, fnn]\n",
    "clf_str = ['KNN', 'SVC', 'RFC', 'FNN']\n",
    "# Parameter grids for GridSearch\n",
    "knn_params = {'n_neighbors':[1,3,5,8,10]}\n",
    "svc_params = {'C': [1, 10, 100],\n",
    "              'gamma': [0.1,1],\n",
    "              'kernel': ['rbf'],\n",
    "              'probability':[True],\n",
    "              'random_state':[0]}\n",
    "rfc_params = {'n_estimators':[100,300,500,700],\n",
    "              'max_depth':[5,7,10],\n",
    "              'random_state':[0]}\n",
    "fnn_params = {'hidden_layer_sizes': [(100,), (50, 50), (30, 30, 30)],\n",
    "              'activation': ['relu', 'tanh'],\n",
    "              'alpha': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "params = pd.Series(data=[knn_params, svc_params, rfc_params, fnn_params],\n",
    "                   index=clf)\n",
    "\n",
    "ensemble_clf = VotingClassifier(estimators=list(zip(clf_str, clf)), voting='soft')\n",
    "\n",
    "# Tune hyperparameters with GridSearch for the ensemble\n",
    "ensemble_params = {'voting': ['soft', 'hard']}\n",
    "\n",
    "# Add ensemble classifier and its parameters to the list\n",
    "clf.append(ensemble_clf)\n",
    "clf_str.append('Ensemble')\n",
    "params[ensemble_clf] = ensemble_params\n",
    "\n",
    "# Tune hyperparameters with GridSearch (estimated time 8m)\n",
    "print('GridSearch start')\n",
    "fitted_models_multi = []\n",
    "for model, model_name in zip(clf, clf_str):\n",
    "    print('Training '+str(model_name))\n",
    "    fit_model = tune_and_fit(model,X_train,y_train,params[model],'binary')\n",
    "    fitted_models_multi.append(fit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['Not Failure', 'Failure']\n",
    "# Create evaluation metrics\n",
    "task = 'binary'\n",
    "y_pred_val, cm_dict_val, metrics_val = predict_and_evaluate(fitted_models_multi, X_val, y_val, clf_str, task)\n",
    "y_pred_test, cm_dict_test, metrics_test = predict_and_evaluate(fitted_models_multi, X_test, y_test, clf_str, task)\n",
    "\n",
    "# Show Confusion Matrices and Metrics for Validation and Test Sets\n",
    "sets = ['Validation', 'Test']\n",
    "\n",
    "for dataset in sets:\n",
    "    if dataset == 'Validation':\n",
    "        cm_dict = cm_dict_val\n",
    "        metrics = metrics_val\n",
    "    else:\n",
    "        cm_dict = cm_dict_test\n",
    "        metrics = metrics_test\n",
    "    fig, axs = plt.subplots(ncols=len(clf_str), figsize=(5 * len(clf_str), 4))\n",
    "    fig.suptitle(f'{dataset} Set Confusion Matrices')\n",
    "    for j, model_name in enumerate(clf_str):\n",
    "        ax = axs[j]\n",
    "        sns.heatmap(ax=ax, data=cm_dict[model_name], annot=True,\n",
    "                    fmt='d', cmap='Blues', cbar=False)\n",
    "        ax.title.set_text(model_name)\n",
    "        ax.set_xticklabels(cm_labels)\n",
    "        ax.set_yticklabels(cm_labels)\n",
    "    plt.show()\n",
    "    # Print scores\n",
    "    print(f'\\n{dataset} scores:', metrics, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Permutation Feature Importances\n",
    "f2_scorer = make_scorer(fbeta_score, pos_label=1, beta=2)\n",
    "importances = pd.DataFrame()\n",
    "for clf in fitted_models_multi:\n",
    "    result = permutation_importance(clf, X_train,y_train['Target'],\n",
    "                                  scoring=f2_scorer,random_state=0)\n",
    "    result_mean = pd.Series(data=result.importances_mean, index=X.columns)\n",
    "    importances = pd.concat(objs=[importances,result_mean],axis=1)\n",
    "importances.columns = clf_str\n",
    "\n",
    "# Barplot of Feature Importances\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(20,4))\n",
    "fig.suptitle('Permutation Feature Importances')\n",
    "for j, name in enumerate(importances.columns):\n",
    "    sns.barplot(ax=axs[j], x=importances.index, y=importances[name].values)\n",
    "    axs[j].tick_params('x',labelrotation=90)\n",
    "    axs[j].set_ylabel('Importances')\n",
    "    axs[j].title.set_text(str(name))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
