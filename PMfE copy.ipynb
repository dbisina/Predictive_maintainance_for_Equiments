{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, fbeta_score\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data_path = 'https://raw.githubusercontent.com/Rapo-zevs/eda/main/predictive_maintenance.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "n = data.shape[0]\n",
    "# First checks\n",
    "\n",
    "data.info()\n",
    "print('Number of null values is: {}'.format(data.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set numeric columns dtype to float\n",
    "data['Tool wear [min]'] = data['Tool wear [min]'].astype('float64')\n",
    "data['Rotational speed [rpm]'] = data['Rotational speed [rpm]'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID columns\n",
    "df = data.copy()\n",
    "df.drop(columns=['UDI','Product ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pie chart shows the percentages of machines by Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = data['Type'].value_counts()\n",
    "Type_Percentage = 100*value/data.Type.shape[0]\n",
    "labels = Type_Percentage.index.array\n",
    "x = Type_Percentage.array\n",
    "custom_colors = sns.color_palette('Set3', len(labels))\n",
    "plt.pie(x, labels=labels, colors=custom_colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Machine Type percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aberrations Create lists of features and target names\n",
    "df.dtypes\n",
    "features = [col for col in df.columns if df[col].dtype=='float64' or col =='Type']\n",
    "target = ['Target','Failure Type']\n",
    "# Portion of data where Random Failure=1\n",
    "random_fail_index=df.loc[df['Failure Type']=='Random Failures'].index\n",
    "df.loc[random_fail_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately the machine failure RNF occurs in only 18 observations and it has a random nature\n",
    "therefore not predictable so we decide to remove these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RNF\n",
    "df.drop(index=random_fail_index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward we find out that in 9 observations Machine failure is set to 1 when all types\n",
    "of failures are set to 0. We cannot understand if there really was a failure or not so letâ€™s remove\n",
    "these observations too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portion of data where Machine failure=1 but no failure cause is specified\n",
    "ambiguous_index = df.loc[(df['Target']==1) & (df['Failure Type']=='No Failure')].index\n",
    "second_drop = df.loc[ambiguous_index].shape[0]\n",
    "display(df.loc[ambiguous_index,target])\n",
    "df.drop(index=ambiguous_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global percentage of removed observations\n",
    "print('Global percentage of removed observations:',\n",
    "     (100*(data.size-df.size)/data.size))\n",
    "df.reset_index(drop=True, inplace=True)   # Reset index\n",
    "n = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers inspection <a id=\"outliers\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [feature for feature in features if df[feature].dtype=='float64']\n",
    "# boxplot of numeric features\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18,7))\n",
    "fig.suptitle('Numeric features boxplot')\n",
    "for j, feature in enumerate(num_features):\n",
    "    sns.boxplot(ax=axs[j//3, j-3*(j//3)], data=df, x=feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers_custom(dataframe, column_name, lower_threshold, upper_threshold):\n",
    "    # Filter the DataFrame to keep only the data points within the specified range\n",
    "    dataframe_filtered = dataframe[(dataframe[column_name] >= lower_threshold) & (dataframe[column_name] <= upper_threshold)]\n",
    "    return dataframe_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_outliers_custom(df, 'Rotational speed [rpm]', 1300, 2250)\n",
    "sns.boxplot(x='Rotational speed [rpm]', data=df)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_outliers_custom(df, 'Torque [Nm]', 12, 73)\n",
    "sns.boxplot(x='Torque [Nm]', data=df)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling with SMOTE <a id=\"resampling\"></a>\n",
    "\n",
    "Another important consideration regards the extremely low occurrence of machine failures among\n",
    "the entire dataset, which percentage is equal only to 3.31%. Moreover, a pie plot showing the\n",
    "occurrence of the causes involved for each failure reveals a further degree of imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portion of df where there is a failure and causes percentage\n",
    "fail_index = df.loc[df['Failure Type'] != 'No Failure'].index\n",
    "df_fail = df.loc[fail_index]\n",
    "df_fail_percentage = 100*df_fail['Failure Type'].value_counts()/df_fail['Failure Type'].shape[0]\n",
    "# Pie plot\n",
    "plt.title('Causes involved in Machine failures')\n",
    "plt.pie(x=df_fail_percentage.array, labels=df_fail_percentage.index.array,\n",
    "        colors=sns.color_palette('tab10')[0:4], autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "# n_working must represent 80% of the desired length of resampled dataframe\n",
    "n_working = df['Failure Type'].value_counts()['No Failure']\n",
    "desired_length = round(n_working/0.8)\n",
    "spc = round((desired_length-n_working)/4)  #samples per class\n",
    "# Resampling\n",
    "balance_cause = {'No Failure':n_working,\n",
    "                 'Overstrain Failure':spc,\n",
    "                 'Heat Dissipation Failure':spc,\n",
    "                 'Power Failure':spc,\n",
    "                 'Tool Wear Failure':spc}\n",
    "sm = SMOTENC(categorical_features=[0,7], sampling_strategy=balance_cause, random_state=0)\n",
    "df_res, y_res = sm.fit_resample(df, df['Failure Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison after resampling <a id=\"resample_comparison\"></a>\n",
    "\n",
    "The result is described in the following pie charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portion of df_res where there is a failure and causes percentage\n",
    "idx_fail_res = df_res.loc[df_res['Failure Type'] != 'No Failure'].index\n",
    "df_res_fail = df_res.loc[idx_fail_res]\n",
    "fail_res_percentage = 100*df_res_fail['Failure Type'].value_counts()/df_res_fail.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "fig.suptitle('Causes involved in Machine failures')\n",
    "\n",
    "# Create bar charts on the first subplot\n",
    "axs[0].bar(df_fail_percentage.index.array, df_fail_percentage.array, color=sns.color_palette('tab10')[0:4])\n",
    "axs[0].set_ylabel('Percentage')\n",
    "axs[0].set_title('Original')\n",
    "\n",
    "# Create bar charts on the second subplot\n",
    "axs[1].bar(fail_res_percentage.index.array, fail_res_percentage.array, color=sns.color_palette('tab10')[0:4])\n",
    "axs[1].set_ylabel('Percentage')\n",
    "axs[1].set_title('After Resampling')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features scaling and Encoding <a id=\"encoding\"></a>\n",
    "\n",
    "In order to make data exploitable for the algorithms we will run, we apply two transformations:\n",
    "* First, we apply a label encoding to the categorical columns, since Type is an ordinal feature\n",
    "and Cause must be represented in one column. The mapping follows this scheme:\n",
    "Type: {L=0, M=1, H=2}\n",
    "Cause: {Working=0, PWF=1, OSF=2, HDF=3, TWF=4}\n",
    "* Secondly we perform the scaling of the columns with StandardScaler. This is particularly\n",
    "useful for the good working of methods that rely on the metric space, such as PCA and KNN.\n",
    "It has been also verified that using StandardScaler leads to slightly better performances than\n",
    "using MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "sc = StandardScaler()\n",
    "types = {'L': 0, 'M': 1, 'H': 2}\n",
    "causes = {'No Failure': 0,'Power Failure': 1,'Overstrain Failure': 2,'Heat Dissipation Failure': 3,'Tool Wear Failure': 4}\n",
    "df_pre = df_res.copy()\n",
    "# Encoding\n",
    "df_pre['Type'].replace(to_replace=types, inplace=True)\n",
    "df_pre['Failure Type'].replace(to_replace=causes, inplace=True)\n",
    "# Scaling\n",
    "df_pre[num_features] = sc.fit_transform(df_pre[num_features]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA and Correlation Heatmap <a id=\"pca\"></a>\n",
    "\n",
    "We run PCA to have a further way of displaying the data instead of making feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=len(num_features))\n",
    "X_pca = pd.DataFrame(data=pca.fit_transform(df_pre[num_features]), columns=['PC'+str(i+1) for i in range(len(num_features))])\n",
    "var_exp = pd.Series(data=100*pca.explained_variance_ratio_, index=['PC'+str(i+1) for i in range(len(num_features))])\n",
    "print('Explained variance ratio per component:', round(var_exp,2), sep='\\n=')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings Analysis\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(18, 4))\n",
    "fig.suptitle('Loadings magnitude')\n",
    "pca_loadings = pd.DataFrame(data=pca.components_, columns=num_features)\n",
    "\n",
    "for j in range(3):\n",
    "    ax = axs[j]\n",
    "    loadings_data = pca_loadings.values[j]\n",
    "    positive_loadings = np.maximum(0, loadings_data)\n",
    "    negative_loadings = np.minimum(0, loadings_data)\n",
    "    \n",
    "    x = np.arange(len(num_features))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x, positive_loadings, width, label='Positive', color='b')\n",
    "    ax.bar(x, negative_loadings, width, label='Negative', color='r')\n",
    "    \n",
    "    ax.set_xlabel('Features')\n",
    "    ax.set_ylabel('Loadings')\n",
    "    ax.set_title('PC' + str(j + 1))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(num_features, rotation=90)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot of Principal Components weights makes easy to understand what they represent:\n",
    "* PC1 is closely related to the two temperature data;\n",
    "* PC2 can be identified with the machine power, which is the product of Rotational Speed\n",
    "and Torque;\n",
    "* PC3 is identifiable with Tool Wear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection into the space generated by these three axes highlights that:\n",
    "* TWF is the class of failures best separated from all the others and seems to depend almost\n",
    "entirely on PC3 (Tool Wear);\n",
    "* PWF occupies two extreme bands along the PC2 (Power), it is independent of the other\n",
    "two components;\n",
    "18\n",
    "* The OSF and HDF classes are less separated than the others even if it can be observed\n",
    "that the first is characterized by a high Tool Wear and low power while the second is\n",
    "characterized by a high temperature and a low power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.heatmap(data=df_pre.corr(), mask=np.triu(df_pre.corr()), annot=True, cmap='BrBG')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, we observe that the features related to temperature, as well as those related to\n",
    "power, are widely correlated. Furthermore, Tool Wear correlates well with both of our targets,\n",
    "confirming what we have observed by studying PCA. Finally, a less strong correlation is also\n",
    "observed between the torsion and the two targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Binary task** <a id=\"binary\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation-test split\n",
    "X, y = df_pre[features], df_pre[['Target', 'Failure Type']]\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(model, X_train, y_train, X_val, y_val):\n",
    "    t = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    elapsed = time.time() - t\n",
    "    print(f'Elapsed time: {elapsed:.4f} s')\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f2 = fbeta_score(y_val, y_pred, beta=2)\n",
    "\n",
    "    print('Validation Accuracy:', accuracy)\n",
    "    print('Validation ROC AUC Score:', auc)\n",
    "    print('Validation F1 Score:', f1)\n",
    "    print('Validation F2 Score:', f2)\n",
    "\n",
    "    return model, accuracy, auc, f1, f2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models <a id=\"binary_models\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(probability=True),\n",
    "    MLPClassifier(max_iter=500)\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_f2_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "for model in models:\n",
    "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "    trained_model, accuracy, auc, f1, f2 = classification(model, X_train, y_train['Target'], X_val, y_val['Target'])\n",
    "\n",
    "    if f2 > best_f2_score:\n",
    "        best_model = trained_model\n",
    "        best_f2_score = f2\n",
    "\n",
    "print(f'\\nBest model: {best_model.__class__.__name__} with F2 Score: {best_f2_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test['Target'], y_test_pred)\n",
    "test_auc = roc_auc_score(y_test['Target'], y_test_pred)\n",
    "test_f1 = f1_score(y_test['Target'], y_test_pred)\n",
    "test_f2 = fbeta_score(y_test['Target'], y_test_pred, beta=2)\n",
    "\n",
    "print(f'\\nTest Accuracy: {test_accuracy}')\n",
    "print(f'Test ROC AUC Score: {test_auc}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test F2 Score: {test_f2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation feature importance\n",
    "perm_importance = permutation_importance(best_model, X_val, y_val['Target'])\n",
    "feature_importance = pd.Series(perm_importance.importances_mean, index=features)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=feature_importance, y=feature_importance.index, palette='viridis')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "def plot_predictions(y_true, y_pred, title='Predictions vs Actual'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(y_true.reset_index(drop=True), label='Actual')\n",
    "    plt.plot(y_pred, label='Predicted', linestyle='--')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Machine Failure')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plot_predictions(y_test['Target'], y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results = {\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_auc': test_auc,\n",
    "    'test_f1': test_f1,\n",
    "    'test_f2': test_f2\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict a single row\n",
    "def predict_single_row(row, model, scaler, encoder_dict):\n",
    "    # Encode and scale the row\n",
    "    row_copy = row.copy()\n",
    "    row_copy['Type'] = row_copy['Type'].replace(encoder_dict['types'])\n",
    "    row_copy[num_features] = scaler.transform([row_copy[num_features]])\n",
    "    return model.predict(row_copy[features].values.reshape(1, -1))\n",
    "\n",
    "# Example usage of the prediction function\n",
    "# Single row from test set\n",
    "single_row = X_test.iloc[0]\n",
    "predicted_label = predict_single_row(single_row, best_model, sc, {'types': types})\n",
    "print(f'Predicted label for single row: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
