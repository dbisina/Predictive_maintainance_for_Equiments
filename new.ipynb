{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, fbeta_score, confusion_matrix, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "# Import data\n",
    "data_path = 'https://raw.githubusercontent.com/Rapo-zevs/eda/main/predictive_maintenance.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "n = data.shape[0]\n",
    "\n",
    "# First checks\n",
    "data.info()\n",
    "print('Number of null values is: {}'.format(data.isnull().sum().sum()))\n",
    "\n",
    "# Set numeric columns dtype to float\n",
    "data['Tool wear [min]'] = data['Tool wear [min]'].astype('float64')\n",
    "data['Rotational speed [rpm]'] = data['Rotational speed [rpm]'].astype('float64')\n",
    "\n",
    "# Drop ID columns\n",
    "df = data.copy()\n",
    "df.drop(columns=['UDI', 'Product ID'], inplace=True)\n",
    "\n",
    "# The following pie chart shows the percentages of machines by Type:\n",
    "value = data['Type'].value_counts()\n",
    "Type_Percentage = 100 * value / data.Type.shape[0]\n",
    "labels = Type_Percentage.index.array\n",
    "x = Type_Percentage.array\n",
    "custom_colors = sns.color_palette('Set3', len(labels))\n",
    "plt.pie(x, labels=labels, colors=custom_colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Machine Type percentage')\n",
    "plt.show()\n",
    "\n",
    "# Create lists of features and target names\n",
    "df.dtypes\n",
    "features = [col for col in df.columns if df[col].dtype == 'float64' or col == 'Type']\n",
    "target = ['Target', 'Failure Type']\n",
    "\n",
    "# Portion of data where Random Failure=1\n",
    "random_fail_index = df.loc[df['Failure Type'] == 'Random Failures'].index\n",
    "df.loc[random_fail_index]\n",
    "\n",
    "# Drop RNF\n",
    "df.drop(index=random_fail_index, inplace=True)\n",
    "\n",
    "# Portion of data where Machine failure=1 but no failure cause is specified\n",
    "ambiguous_index = df.loc[(df['Target'] == 1) & (df['Failure Type'] == 'No Failure')].index\n",
    "second_drop = df.loc[ambiguous_index].shape[0]\n",
    "display(df.loc[ambiguous_index, target])\n",
    "df.drop(index=ambiguous_index, inplace=True)\n",
    "\n",
    "# Global percentage of removed observations\n",
    "print('Global percentage of removed observations:', (100 * (data.size - df.size) / data.size))\n",
    "df.reset_index(drop=True, inplace=True)  # Reset index\n",
    "n = df.shape[0]\n",
    "\n",
    "# Outliers inspection\n",
    "num_features = [feature for feature in features if df[feature].dtype == 'float64']\n",
    "# boxplot of numeric features\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18, 7))\n",
    "fig.suptitle('Numeric features boxplot')\n",
    "for j, feature in enumerate(num_features):\n",
    "    sns.boxplot(ax=axs[j // 3, j - 3 * (j // 3)], data=df, x=feature)\n",
    "plt.show()\n",
    "\n",
    "def drop_outliers_custom(dataframe, column_name, lower_threshold, upper_threshold):\n",
    "    # Filter the DataFrame to keep only the data points within the specified range\n",
    "    dataframe_filtered = dataframe[(dataframe[column_name] >= lower_threshold) & (dataframe[column_name] <= upper_threshold)]\n",
    "    return dataframe_filtered\n",
    "\n",
    "df = drop_outliers_custom(df, 'Rotational speed [rpm]', 1300, 2250)\n",
    "sns.boxplot(x='Rotational speed [rpm]', data=df)\n",
    "plt.show()\n",
    "df = drop_outliers_custom(df, 'Torque [Nm]', 12, 73)\n",
    "sns.boxplot(x='Torque [Nm]', data=df)\n",
    "plt.show()\n",
    "\n",
    "# Resampling with SMOTE\n",
    "# Portion of df where there is a failure and causes percentage\n",
    "fail_index = df.loc[df['Failure Type'] != 'No Failure'].index\n",
    "df_fail = df.loc[fail_index]\n",
    "df_fail_percentage = 100 * df_fail['Failure Type'].value_counts() / df_fail['Failure Type'].shape[0]\n",
    "\n",
    "# Pie plot\n",
    "plt.title('Causes involved in Machine failures')\n",
    "plt.pie(x=df_fail_percentage.array, labels=df_fail_percentage.index.array,\n",
    "        colors=sns.color_palette('tab10')[0:4], autopct='%.0f%%')\n",
    "plt.show()\n",
    "\n",
    "# n_working must represent 80% of the desired length of resampled dataframe\n",
    "n_working = df['Failure Type'].value_counts()['No Failure']\n",
    "desired_length = round(n_working / 0.8)\n",
    "spc = round((desired_length - n_working) / 4)  # samples per class\n",
    "\n",
    "# Resampling\n",
    "balance_cause = {'No Failure': n_working,\n",
    "                 'Overstrain Failure': spc,\n",
    "                 'Heat Dissipation Failure': spc,\n",
    "                 'Power Failure': spc,\n",
    "                 'Tool Wear Failure': spc}\n",
    "\n",
    "sm = SMOTENC(categorical_features=[0, 7], sampling_strategy=balance_cause, random_state=0)\n",
    "df_res, y_res = sm.fit_resample(df, df['Failure Type'])\n",
    "\n",
    "# Comparison after resampling\n",
    "# Portion of df_res where there is a failure and causes percentage\n",
    "idx_fail_res = df_res.loc[df_res['Failure Type'] != 'No Failure'].index\n",
    "df_res_fail = df_res.loc[idx_fail_res]\n",
    "fail_res_percentage = 100 * df_res_fail['Failure Type'].value_counts() / df_res_fail.shape[0]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "fig.suptitle('Causes involved in Machine failures')\n",
    "\n",
    "# Create bar charts on the first subplot\n",
    "axs[0].bar(df_fail_percentage.index.array, df_fail_percentage.array, color=sns.color_palette('tab10')[0:4])\n",
    "axs[0].set_ylabel('Percentage')\n",
    "axs[0].set_title('Original')\n",
    "\n",
    "# Create bar charts on the second subplot\n",
    "axs[1].bar(fail_res_percentage.index.array, fail_res_percentage.array, color=sns.color_palette('tab10')[0:4])\n",
    "axs[1].set_ylabel('Percentage')\n",
    "axs[1].set_title('After Resampling')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Features scaling and Encoding\n",
    "# Encoding\n",
    "sc = StandardScaler()\n",
    "types = {'L': 0, 'M': 1, 'H': 2}\n",
    "causes = {'No Failure': 0, 'Power Failure': 1, 'Overstrain Failure': 2, 'Heat Dissipation Failure': 3, 'Tool Wear Failure': 4}\n",
    "df_pre = df_res.copy()\n",
    "df_pre['Type'].replace(to_replace=types, inplace=True)\n",
    "df_pre['Failure Type'].replace(to_replace=causes, inplace=True)\n",
    "df_pre[num_features] = sc.fit_transform(df_pre[num_features])\n",
    "\n",
    "# PCA and Correlation Heatmap\n",
    "pca = PCA(n_components=len(num_features))\n",
    "X_pca = pd.DataFrame(data=pca.fit_transform(df_pre[num_features]), columns=['PC' + str(i + 1) for i in range(len(num_features))])\n",
    "var_exp = pd.Series(data=100 * pca.explained_variance_ratio_, index=['PC' + str(i + 1) for i in range(len(num_features))])\n",
    "print('Explained variance ratio per component:', round(var_exp, 2), sep='\\n=')\n",
    "\n",
    "# Loadings Analysis\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(18, 4))\n",
    "fig.suptitle('Loadings magnitude')\n",
    "pca_loadings = pd.DataFrame(data=pca.components_, columns=num_features)\n",
    "\n",
    "for j in range(3):\n",
    "    ax = axs[j]\n",
    "    loadings_data = pca_loadings.values[j]\n",
    "    positive_loadings = np.maximum(0, loadings_data)\n",
    "    negative_loadings = np.minimum(0, loadings_data)\n",
    "\n",
    "    x = np.arange(len(num_features))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(x, positive_loadings, width, label='Positive', color='b')\n",
    "    ax.bar(x, negative_loadings, width, label='Negative', color='r')\n",
    "\n",
    "    ax.set_xlabel('Features')\n",
    "    ax.set_ylabel('Loadings')\n",
    "    ax.set_title('PC' + str(j + 1))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(num_features, rotation=90)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.heatmap(data=df_pre.corr(), mask=np.triu(df_pre.corr()), annot=True, cmap='BrBG')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Binary task\n",
    "# train-validation-test split\n",
    "X, y = df_pre[features], df_pre[['Target', 'Failure Type']]\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "def classification(model, X_train, y_train, X_val, y_val):\n",
    "    t = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    elapsed = time.time() - t\n",
    "    print(f'Elapsed time: {elapsed:.4f} s')\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f2 = fbeta_score(y_val, y_pred, beta=2)\n",
    "\n",
    "    print('Validation Accuracy:', accuracy)\n",
    "    print('Validation ROC AUC Score:', auc)\n",
    "    print('Validation F1 Score:', f1)\n",
    "    print('Validation F2 Score:', f2)\n",
    "\n",
    "    return model, accuracy, auc, f1, f2\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(probability=True),\n",
    "    MLPClassifier(max_iter=500)\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_f2_score = 0\n",
    "\n",
    "# Compare models\n",
    "for model in models:\n",
    "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "    trained_model, accuracy, auc, f1, f2 = classification(model, X_train, y_train['Target'], X_val, y_val['Target'])\n",
    "\n",
    "    if f2 > best_f2_score:\n",
    "        best_model = trained_model\n",
    "        best_f2_score = f2\n",
    "\n",
    "print(f'\\nBest model: {best_model.__class__.__name__} with F2 Score: {best_f2_score}')\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test['Target'], y_test_pred)\n",
    "test_auc = roc_auc_score(y_test['Target'], y_test_pred)\n",
    "test_f1 = f1_score(y_test['Target'], y_test_pred)\n",
    "test_f2 = fbeta_score(y_test['Target'], y_test_pred, beta=2)\n",
    "\n",
    "print(f'\\nTest Accuracy: {test_accuracy}')\n",
    "print(f'Test ROC AUC Score: {test_auc}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test F2 Score: {test_f2}')\n",
    "\n",
    "# Permutation feature importance\n",
    "perm_importance = permutation_importance(best_model, X_val, y_val['Target'])\n",
    "feature_importance = pd.Series(perm_importance.importances_mean, index=features)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=feature_importance, y=feature_importance.index, palette='viridis')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "# Plotting function\n",
    "def plot_predictions(y_true, y_pred, title='Predictions vs Actual'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(y_true.reset_index(drop=True), label='Actual')\n",
    "    plt.plot(y_pred, label='Predicted', linestyle='--')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Machine Failure')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot results\n",
    "plot_predictions(y_test['Target'], y_test_pred)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_auc': test_auc,\n",
    "    'test_f1': test_f1,\n",
    "    'test_f2': test_f2\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
